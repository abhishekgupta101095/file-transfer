from airflow import DAG
from airflow.providers.amazon.aws.operators.s3 import S3ListOperator
from airflow.operators.dummy_operator import DummyOperator
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from airflow.providers.amazon.aws.hooks.s3 import S3Hook
from airflow.providers.microsoft.azure.hooks.wasb import WasbHook
from datetime import datetime, timedelta
import airflow.utils.dates

import os
from pathlib import Path

from airflow.providers.google.cloud.transfers.gcs_to_local import GCSToLocalFilesystemOperator
from airflow.utils.trigger_rule import TriggerRule

from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator

import scripts.config as config

from scripts.s3_processing_python import process_s3
from scripts.DataQualityChecks import dataQualityChecksProcess

import boto3
from scripts.invidual_data_ingestion_3p import individual_process_3p
from airflow.operators.python import BranchPythonOperator

from scripts.segment_demo_insights_view_ingestion import segment_demo_insights_view_process
from scripts.segment_profile_web import segment_profile_web_view_process
from scripts.segment_profile_poi import segment_profile_poi_view_process
from scripts.segment_profile_app import segment_profile_app_view_process
from scripts.segment_profile_social import segment_profile_social_view_process
 
from scripts.audience_demo_insights import audience_demo_insights_view_process
from scripts.audience_profile_poi import location_visited_view_process
from scripts.audience_profile_app import audience_profile_app_view_process
from scripts.audience_analytics import insert_data_load_metadata, create_audience_analytics_view_process
from scripts.aa_web_view import aa_web_view_process
from scripts.aa_social_view import aa_social_view_process

from scripts.idr_demo_insights import idr_demo_insights_view_process
from scripts.idr_profile_app import idr_profile_app_view_process
from scripts.idr_web_view import idr_web_view_process
from scripts.idr_social_view import idr_social_view_process
from scripts.idr_profile_poi import idr_profile_poi_view_process
from scripts.idr_demo_summary import idr_demo_summary_view_process

from airflow.sensors.external_task_sensor import ExternalTaskSensor

from scripts.individual_geographics_view import individual_geographics_view_process
from scripts.segment_geographics_view import segment_geographics_view_process

BUCKET_NAME=config.bucketName
METADATA_LOCAL_PATH=config.locatPathToDownloadDictionaryFiles
S3_DICTIONARY_PREFIX=config.s3DictionaryPrefix
S3_DELIMITER=config.s3Delimiter
AWS_CONN_ID=config.awsConnId

BUCKET_NAME=config.bucketName
RAWDATA_LOCAL_PATH=config.locatPathToDownloadRawFiles
S3_RAW_FILES_PREFIX=config.s3RawFilesPrefix
S3_DELIMITER=config.s3Delimiter
AWS_CONN_ID=config.awsConnId
aws_access_key_id=config.aws_access_key_id
aws_secret_access_key=config.aws_secret_access_key
aws_region=config.aws_region
s3_processed_path=config.s3_processed_path

default_args = {
        "owner": "airflow", 
        "start_date": airflow.utils.dates.days_ago(1)
    }

    
def download_from_s3(key: str, s3_prefix: str, localFilePath: str) -> None:
    hook = S3Hook('aws_udm')
    if key == s3_prefix:
        return None
    file_name = hook.download_file(
        key=key,
        bucket_name=BUCKET_NAME,
        preserve_file_name=True,
        local_path=localFilePath,
        use_autogenerated_subdir=False
    )
    # will return absolute path
    return file_name


def move_s3_objects(key: str, s3_prefix: str) -> None:
    if key == s3_prefix:
        return None
    s3 = boto3.client(
        's3',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
        region_name=aws_region
    )
    current_date = datetime.now()
    formatted_date = current_date.strftime('%Y%m%d')
    dirPath = key.rsplit('/', 1)[0]
    fileName = key.rsplit('/', 1)[1]
    newKey = dirPath + '/' + formatted_date + '/' + fileName
    destination_key = newKey.replace(S3_RAW_FILES_PREFIX, s3_processed_path, 1)
    # Copy the object to the new location
    s3.copy_object(
            Bucket=BUCKET_NAME,
            CopySource={'Bucket': BUCKET_NAME, 'Key': key},
            Key=destination_key
        )


def delete_s3_objects(key: str, s3_prefix: str) -> None:
    if key == s3_prefix:
        return None
    s3 = boto3.client(
        's3',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
        region_name=aws_region
    )
    s3.delete_object(Bucket=BUCKET_NAME, Key=key)


default_args = {
        "owner": "airflow", 
        "start_date": airflow.utils.dates.days_ago(1)
    }


def folder_exists(**kwargs):
    current_date = datetime.now()
    formatted_date = current_date.strftime('%Y%m%d')
    path=s3_processed_path+formatted_date
    ti = kwargs['ti']
    s3 = boto3.client(
        's3',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
        region_name=aws_region
    )
    #path = 'CDI/data/raw/20240214'.rstrip('/') 
    resp = s3.list_objects(Bucket=BUCKET_NAME, Prefix=path, Delimiter=S3_DELIMITER,MaxKeys=1)
    if 'CommonPrefixes' in resp:
        ti.xcom_push(key="pushed_value", value='directory_exists')
    else:
        ti.xcom_push(key="pushed_value", value='directory_does_not_exists')


def create_directory(**kwargs):
    pushed_value=5
    current_date = datetime.now()
    formatted_date = current_date.strftime('%Y%m%d')
    directory_path=s3_processed_path+formatted_date
    if not directory_path.endswith('/'):
        directory_path += '/'
    s3 = boto3.client(
        's3',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
        region_name=aws_region
    ) 
    s3.put_object(Bucket=BUCKET_NAME, Key=directory_path)


def branch_function(**kwargs):
    ti = kwargs['ti']
    pulled_value = ti.xcom_pull(key='pushed_value', task_ids='check_folder_exist_task')
    if pulled_value == 'directory_exists':
        return 'hop_task'
    else:
        return 'create_directory_task'


def delete_local_files(filePath: str):
    # Get a list of all files in the directory
    file_list = os.listdir(filePath)
    # Iterate through the list and delete each file
    for file_name in file_list:
        file_path = os.path.join(filePath, file_name)
        try:
            # Delete the file
            os.remove(file_path)
            print(f"File {file_name} has been successfully deleted.")
        except Exception as e:
            print(f"An error occurred while deleting {file_name}: {e}")


with DAG(dag_id="create3PViews", default_args=default_args, schedule_interval=None) as dag:
    
    '''viewCreationsJobSensor = ExternalTaskSensor(
        task_id='viewCreationsJobSensor_task',
        external_dag_id='load3pIndividual',
        external_task_id='end' ,
        poke_interval=5,
        timeout=60 * 10
       )'''
    
    start = DummyOperator(
    task_id='start'
    )
       
    segment_demo_insights_view = PythonOperator(
        task_id='segment_demo_insights_view',
        python_callable=segment_demo_insights_view_process
    )
    
    segment_profile_web_view = PythonOperator(
        task_id='segment_profile_web_view',
        python_callable=segment_profile_web_view_process
    )
    
    segment_profile_poi_view = PythonOperator(
        task_id='segment_profile_poi_view',
        python_callable=segment_profile_poi_view_process
    )
    
    segment_profile_app_view = PythonOperator(
        task_id='segment_profile_app_view',
        python_callable=segment_profile_app_view_process
    )
    
    segment_profile_social_view = PythonOperator(
        task_id='segment_profile_social_view',
        python_callable=segment_profile_social_view_process
    )
    
    audience_demo_insights_view = PythonOperator(
        task_id='audience_demo_insights_view',
        python_callable=audience_demo_insights_view_process
    )
    
    audience_profile_poi_view = PythonOperator(
        task_id='audience_profile_poi_view',
        python_callable=location_visited_view_process
    )
    
    audience_profile_app_view = PythonOperator(
        task_id='audience_profile_app_view',
        python_callable=audience_profile_app_view_process
    )
    
    audience_analytics_view = PythonOperator(
        task_id='audience_analytics_view',
        python_callable=create_audience_analytics_view_process
    )
    
    idr_demo_insights_view = PythonOperator(
        task_id="idr_demo_insights_view",
        python_callable=idr_demo_insights_view_process
    )
    
    idr_profile_app_view = PythonOperator(
        task_id="idr_profile_app_view",
        python_callable=idr_profile_app_view_process
    )
    
    idr_web_view = PythonOperator(
        task_id="idr_web_view",
        python_callable=idr_web_view_process
    )
    
    idr_social_view = PythonOperator(
        task_id="idr_social_view",
        python_callable=idr_social_view_process
    )
    
    idr_profile_poi_view = PythonOperator(
        task_id="idr_profile_poi_view",
        python_callable=idr_profile_poi_view_process
    )

    idr_demo_summary_view = PythonOperator(
        task_id="idr_demo_summary_view",
        python_callable=idr_demo_summary_view_process
    )
    
    insert_data_in_data_load_metadata = PythonOperator(
        task_id='insert_data_in_data_load_metadata',
        python_callable=insert_data_load_metadata
    )
    
    aa_social_view = PythonOperator(
        task_id='aa_social_view',
        python_callable=aa_social_view_process
    )

    aa_web_view = PythonOperator(
        task_id='aa_web_view',
        python_callable=aa_web_view_process
    )

   
    squash = DummyOperator(
    task_id='squash'
    )
    
    delete_local_raw_files = PythonOperator(
        task_id='delete_local_raw_files',
        python_callable=delete_local_files,
        op_kwargs={
            'filePath': RAWDATA_LOCAL_PATH
        }
    )
    
    delete_local_metadata_files = PythonOperator(
        task_id='delete_local_metadata_files',
        python_callable=delete_local_files,
        op_kwargs={
            'filePath': METADATA_LOCAL_PATH
        }
    )

    audience_geographics_view = PythonOperator(
        task_id='audience_geographics_view',
        python_callable=individual_geographics_view_process
    )
    
    segment_geographics_view = PythonOperator(
        task_id='segment_geographics_view',
        python_callable=segment_geographics_view_process
    )
    
    end = DummyOperator(
    task_id='end'
    )

    #load_data_intopostgres = BashOperator(
    #    task_id="load_data_intopostgres",
    #    bash_command="python3 /opt/airflow/dags/scripts/postgreswrite.py"
    #)

start >> [segment_demo_insights_view,segment_profile_web_view,segment_profile_poi_view,segment_profile_app_view,segment_profile_social_view,audience_demo_insights_view,audience_profile_poi_view,audience_profile_app_view,audience_analytics_view,insert_data_in_data_load_metadata,aa_social_view,aa_web_view,idr_demo_insights_view,idr_profile_app_view,idr_profile_poi_view,segment_geographics_view,audience_geographics_view] >> squash
squash >> [delete_local_raw_files,delete_local_metadata_files] >> end

